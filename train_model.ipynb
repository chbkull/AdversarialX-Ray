{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.dataset import ChestXrayDataSet, CLASS_NAMES\n",
    "from src.model import DenseNet121\n",
    "from src.utils import compute_AUCs, compute_score_with_logits, tile\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Autoreload modules so that changes to src automatically reflect\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/labels/cleaned.csv\")\n",
    "X, Y = labels.iloc[:, 0], labels.iloc[:, 1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 64\n",
    "DATA_DIR = \"data/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_train, Y = Y_train,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "                              transforms.RandomHorizontalFlip()\n",
    "                              ]))\n",
    "\n",
    "# note that workers take up some amount of VRAM   \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_test, Y = Y_test,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                              ]))\n",
    "    \n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint\n",
      "=> loaded checkpoint\n"
     ]
    }
   ],
   "source": [
    "training = False # Flip to false to simply load pre-trained model\n",
    "CKPT_TRAINED_PATH = \"model-trained.pth\"\n",
    "\n",
    "cudnn.benchmark = True # Fixed input size, enables tuning for optimal use\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialize and load the model\n",
    "model = DenseNet121(N_CLASSES).to(device)\n",
    "\n",
    "if not training:\n",
    "    if os.path.isfile(CKPT_TRAINED_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_TRAINED_PATH)\n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/thibaultwillmann/CheXNet-Pytorch/blob/master/CheXnet.ipynb\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "if training:\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        for i, (images, labels) in enumerate(train_loader, 0): # get the inputs; data is a list of [images, labels]\n",
    "\n",
    "            # images.shape -> [N, 3, 224, 224]\n",
    "            # labels.shape -> [N, 14]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            images = images.cuda()\n",
    "\n",
    "            n_batches, channels, height, width = images.size()\n",
    "            image_batch = torch.autograd.Variable(images.view(-1, channels, height, width))\n",
    "\n",
    "            labels = tile(labels, 0, 1).cuda()\n",
    "                     \n",
    "            outputs = model(image_batch)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            correct += compute_score_with_logits(outputs, labels).sum()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print('Epoch: %d, loss: %.3f, Accuracy: %.3f' %\n",
    "            (epoch + 1, running_loss, 100 * correct / total))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().to(device)\n",
    "pred = torch.FloatTensor().to(device)\n",
    "\n",
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "for i, (inp, target) in enumerate(test_loader):\n",
    "    target = target.cuda()\n",
    "    gt = torch.cat((gt, target), 0)\n",
    "    bs, c, h, w = inp.size()\n",
    "    with torch.no_grad():\n",
    "        input_var = torch.autograd.Variable(inp.view(-1, c, h, w).cuda())\n",
    "        output = model(input_var)\n",
    "        output_mean = output.view(bs, 1, -1).mean(1)\n",
    "        pred = torch.cat((pred, output_mean.data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average AUROC is 0.832\n",
      "The AUROC of Atelectasis is 0.8439077879845739\n",
      "The AUROC of Cardiomegaly is 0.9556624963808421\n",
      "The AUROC of Effusion is 0.8795635817106547\n",
      "The AUROC of Infiltration is 0.78179352343567\n",
      "The AUROC of Mass is 0.8491913647572664\n",
      "The AUROC of Nodule is 0.8024044557440636\n",
      "The AUROC of Pneumonia is 0.6726941681613131\n",
      "The AUROC of Pneumothorax is 0.8660213682820934\n",
      "The AUROC of Consolidation is 0.7400722681767539\n",
      "The AUROC of Edema is 0.8802701754573411\n",
      "The AUROC of Emphysema is 0.8807207977546327\n",
      "The AUROC of Fibrosis is 0.8253416567675599\n",
      "The AUROC of Pleural_Thickening is 0.7445453324703031\n",
      "The AUROC of Hernia is 0.9267122239328704\n"
     ]
    }
   ],
   "source": [
    "AUROCs = compute_AUCs(gt, pred, N_CLASSES)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "  print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    torch.save(model.state_dict(), \"model-trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35812f3549a68c0c80e102abdb5fbba8158579bbfb7e11bdbba8ac28992cc519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
