{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.dataset import ChestXrayDataSet, CLASS_NAMES\n",
    "from src.model import DenseNet121\n",
    "from src.utils import compute_AUCs, compute_score_with_logits, tile\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Autoreload modules so that changes to src automatically reflect\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/labels/cleaned.csv\")\n",
    "size = 10000 # only using 10k out of 30k cleaned dataset\n",
    "X, Y = labels.iloc[:size, 0], labels.iloc[:size, 1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 16\n",
    "DATA_DIR = \"data/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_train, Y = Y_train,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.TenCrop(224),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                              ]))\n",
    "\n",
    "# note that workers take up some amount of VRAM   \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_test, Y = Y_test,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.TenCrop(224),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                              ]))\n",
    "    \n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint\n",
      "=> loaded checkpoint\n"
     ]
    }
   ],
   "source": [
    "training = True # Flip to false to simply load pre-trained model\n",
    "CKPT_PATH = \"model.pth.tar\" # Starter model from https://github.com/arnoweng/CheXNet\n",
    "CKPT_TRAINED_PATH = \"model-trained.pth\" # Model trained on top of ^\n",
    "cudnn.benchmark = True # Fixed input size, enables tuning for optimal use\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialize and load the model\n",
    "model = DenseNet121(N_CLASSES).to(device)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "if training:\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")\n",
    "else:\n",
    "    if os.path.isfile(CKPT_TRAINED_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_TRAINED_PATH)\n",
    "        # Load directly into the module else the model gets screwed up\n",
    "        # https://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/15\n",
    "        model.module.load_state_dict(checkpoint, strict=True)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 77.849, Accuracy: 35.882\n",
      "Epoch: 2, loss: 69.809, Accuracy: 43.637\n",
      "Epoch: 3, loss: 64.373, Accuracy: 48.875\n",
      "Epoch: 4, loss: 58.172, Accuracy: 54.997\n",
      "Epoch: 5, loss: 51.127, Accuracy: 61.718\n",
      "Epoch: 6, loss: 44.577, Accuracy: 67.552\n",
      "Epoch: 7, loss: 41.584, Accuracy: 70.050\n",
      "Epoch: 8, loss: 36.365, Accuracy: 74.603\n",
      "Epoch: 9, loss: 31.597, Accuracy: 78.473\n",
      "Epoch: 10, loss: 27.511, Accuracy: 82.070\n",
      "Epoch: 11, loss: 22.792, Accuracy: 86.053\n",
      "Epoch: 12, loss: 19.135, Accuracy: 88.822\n",
      "Epoch: 13, loss: 16.369, Accuracy: 90.902\n",
      "Epoch: 14, loss: 13.373, Accuracy: 93.155\n",
      "Epoch: 15, loss: 10.329, Accuracy: 95.245\n",
      "Epoch: 16, loss: 8.423, Accuracy: 96.185\n",
      "Epoch: 17, loss: 6.717, Accuracy: 97.217\n",
      "Epoch: 18, loss: 5.424, Accuracy: 97.830\n",
      "Epoch: 19, loss: 4.028, Accuracy: 98.590\n",
      "Epoch: 20, loss: 2.796, Accuracy: 99.265\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Source: https://github.com/thibaultwillmann/CheXNet-Pytorch/blob/master/CheXnet.ipynb\n",
    "# use_amp = True\n",
    "# scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "if training:\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # RMSprop, Adam\n",
    "\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        for i, (images, labels) in enumerate(train_loader, 0): # get the inputs; data is a list of [images, labels]\n",
    "\n",
    "            # images.shape -> [N, 10, 3, 224, 224]\n",
    "            # labels.shape -> [N, 15]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            images = images.cuda()\n",
    "\n",
    "            # format input\n",
    "            n_batches, n_crops, channels, height, width = images.size()\n",
    "            image_batch = torch.autograd.Variable(images.view(-1, channels, height, width)) # 10N images: N batches contain 10 crops each decomposed into 10N images\n",
    "\n",
    "            labels = tile(labels, 0, 10).cuda() # duplicate for each crop the label [1,2],[3,4] => [1,2],[1,2],[3,4],[3,4] -> 10N labels\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            # TODO: possibly use torch.cuda.amp?            \n",
    "            outputs = model(image_batch)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            correct += compute_score_with_logits(outputs, labels).sum()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print('Epoch: %d, loss: %.3f, Accuracy: %.3f' %\n",
    "            (epoch + 1, running_loss, 100 * correct / total))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor().to(device)\n",
    "pred = torch.FloatTensor().to(device)\n",
    "\n",
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "for i, (inp, target) in enumerate(test_loader):\n",
    "    target = target.cuda()\n",
    "    gt = torch.cat((gt, target), 0)\n",
    "    bs, n_crops, c, h, w = inp.size()\n",
    "    with torch.no_grad():\n",
    "        input_var = torch.autograd.Variable(inp.view(-1, c, h, w).cuda())\n",
    "        # output = torch.sigmoid(model(input_var))\n",
    "        output = model(input_var)\n",
    "        output_mean = output.view(bs, n_crops, -1).mean(1)\n",
    "        pred = torch.cat((pred, output_mean.data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average AUROC is 0.763\n",
      "The AUROC of Atelectasis is 0.7893153167636008\n",
      "The AUROC of Cardiomegaly is 0.9275282030620466\n",
      "The AUROC of Effusion is 0.8232625830343376\n",
      "The AUROC of Infiltration is 0.7210117218229494\n",
      "The AUROC of Mass is 0.7808354015878997\n",
      "The AUROC of Nodule is 0.7699040625942075\n",
      "The AUROC of Pneumonia is 0.5561091490077363\n",
      "The AUROC of Pneumothorax is 0.8034585436385764\n",
      "The AUROC of Consolidation is 0.6646448077581699\n",
      "The AUROC of Edema is 0.777660759493671\n",
      "The AUROC of Emphysema is 0.819904729692705\n",
      "The AUROC of Fibrosis is 0.7708130023028051\n",
      "The AUROC of Pleural_Thickening is 0.7091529809976412\n",
      "The AUROC of Hernia is 0.7686673363468944\n"
     ]
    }
   ],
   "source": [
    "AUROCs = compute_AUCs(gt, pred, N_CLASSES)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "  print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    torch.save(model.module.state_dict(), \"model-trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35812f3549a68c0c80e102abdb5fbba8158579bbfb7e11bdbba8ac28992cc519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
