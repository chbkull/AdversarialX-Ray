{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.densenet import DenseNet121_Weights\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/labels/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 2500\n",
    "X, Y = labels.iloc[:size, 0], labels.iloc[:size, 1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 14\n",
    "BATCH_SIZE = 16\n",
    "CKPT_PATH = \"model.pth.tar\"\n",
    "CKPT_TRAINED_PATH = \"model-trained.pth\"\n",
    "DATA_DIR = \"data/images\"\n",
    "CLASS_NAMES = [ \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\", \"Pneumonia\",\n",
    "\"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        features = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(features, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint\n",
      "=> loaded checkpoint\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "load_trained = True\n",
    "\n",
    "# initialize and load the model\n",
    "model = DenseNet121(N_CLASSES).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "if load_trained:\n",
    "    if os.path.isfile(CKPT_TRAINED_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_TRAINED_PATH)\n",
    "        # Load directly into the module else the model gets screwed up\n",
    "        # https://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/15\n",
    "        model.module.load_state_dict(checkpoint, strict=True)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")\n",
    "else:\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encoding(indices, classes):\n",
    "    x = [0] * classes\n",
    "    if indices is not None:\n",
    "        for index in indices:\n",
    "            x[index] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataSet(Dataset):\n",
    "    def __init__(self, data_dir, X, Y, transform=None):\n",
    "        image_names = []\n",
    "        labels = []\n",
    "\n",
    "        for image_name, label in zip(X, Y):\n",
    "            res = os.path.join(data_dir, image_name)\n",
    "\n",
    "            # Only using subset, skip over images not downloaded\n",
    "            if not os.path.exists(res):\n",
    "                continue\n",
    "\n",
    "            image_names.append(res)\n",
    "\n",
    "            if label == \"No Finding\":\n",
    "                indices = None\n",
    "            else:\n",
    "                indices = [CLASS_NAMES.index(l) for l in label.split('|')]\n",
    "\n",
    "            labels.append(binary_encoding(indices, 14))\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_train, Y = Y_train,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.TenCrop(224),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                              ]))\n",
    "    \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "test_dataset = ChestXrayDataSet(data_dir=DATA_DIR, X = X_test, Y = Y_test,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.TenCrop(224),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                              transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                              ]))\n",
    "    \n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score_with_logits(logits, labels):\n",
    "    logits = torch.max(logits, 1)[1].data # argmax\n",
    "    one_hots = torch.zeros(*labels.size()).cuda()\n",
    "    one_hots.scatter_(1, logits.view(-1, 1), 1)\n",
    "    scores = (one_hots * labels)\n",
    "\n",
    "    return scores\n",
    "  \n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 14.879, Accuracy: 22.840\n",
      "Epoch: 2, loss: 13.989, Accuracy: 24.653\n",
      "Epoch: 3, loss: 13.040, Accuracy: 26.273\n",
      "Epoch: 4, loss: 12.266, Accuracy: 27.700\n",
      "Epoch: 5, loss: 11.584, Accuracy: 29.193\n",
      "Epoch: 6, loss: 10.759, Accuracy: 31.413\n",
      "Epoch: 7, loss: 10.026, Accuracy: 33.773\n",
      "Epoch: 8, loss: 9.326, Accuracy: 36.107\n",
      "Epoch: 9, loss: 8.675, Accuracy: 38.193\n",
      "Epoch: 10, loss: 7.971, Accuracy: 40.613\n",
      "Epoch: 11, loss: 7.257, Accuracy: 42.507\n",
      "Epoch: 12, loss: 6.608, Accuracy: 44.227\n",
      "Epoch: 13, loss: 6.001, Accuracy: 45.513\n",
      "Epoch: 14, loss: 5.278, Accuracy: 46.887\n",
      "Epoch: 15, loss: 4.580, Accuracy: 47.907\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Source: https://github.com/thibaultwillmann/CheXNet-Pytorch/blob/master/CheXnet.ipynb\n",
    "import torch.optim as optim\n",
    "\n",
    "model.train()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)  # RMSprop, Adam\n",
    "\n",
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for i, (images, labels) in enumerate(train_loader, 0): # get the inputs; data is a list of [images, labels]\n",
    "\n",
    "        #images.shape -> [64, 10, 3, 224, 224]\n",
    "        #labels.shape -> [64, 15]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.cuda()\n",
    "\n",
    "        #format input\n",
    "        n_batches, n_crops, channels, height, width = images.size()\n",
    "        image_batch = torch.autograd.Variable(images.view(-1, channels, height, width)) #640 images: 64 batches contain 10 crops each decomposed into 640 images\n",
    "\n",
    "        labels = tile(labels, 0, 10).cuda() #duplicate for each crop the label [1,2],[3,4] => [1,2],[1,2],[3,4],[3,4] -> 640 labels\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(image_batch)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        correct += compute_score_with_logits(outputs, labels).sum()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print('Epoch: %d, loss: %.3f, Accuracy: %.3f' %\n",
    "          (epoch + 1, running_loss, 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ground truth and output tensor\n",
    "gt = torch.FloatTensor()\n",
    "pred = torch.FloatTensor()\n",
    "gt = gt.cuda()\n",
    "pred = pred.cuda()\n",
    "\n",
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "for i, (inp, target) in enumerate(test_loader):\n",
    "    target = target.cuda()\n",
    "    gt = torch.cat((gt, target), 0)\n",
    "    bs, n_crops, c, h, w = inp.size()\n",
    "    with torch.no_grad():\n",
    "        input_var = torch.autograd.Variable(inp.view(-1, c, h, w).cuda())\n",
    "        output = model(input_var)\n",
    "        output_mean = output.view(bs, n_crops, -1).mean(1)\n",
    "        pred = torch.cat((pred, output_mean.data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average AUROC is 0.745\n",
      "The AUROC of Atelectasis is 0.700669290014462\n",
      "The AUROC of Cardiomegaly is 0.8907092198581561\n",
      "The AUROC of Effusion is 0.7755877293577982\n",
      "The AUROC of Infiltration is 0.6111535523300229\n",
      "The AUROC of Mass is 0.7032771638034796\n",
      "The AUROC of Nodule is 0.6414156476786956\n",
      "The AUROC of Pneumonia is 0.6386554621848739\n",
      "The AUROC of Pneumothorax is 0.7512254901960784\n",
      "The AUROC of Consolidation is 0.760587533552043\n",
      "The AUROC of Edema is 0.9207575513707816\n",
      "The AUROC of Emphysema is 0.7393465909090908\n",
      "The AUROC of Fibrosis is 0.6655729166666666\n",
      "The AUROC of Pleural_Thickening is 0.6318512083399147\n",
      "The AUROC of Hernia is 1.0\n"
     ]
    }
   ],
   "source": [
    "AUROCs = compute_AUCs(gt, pred)\n",
    "AUROC_avg = np.array(AUROCs).mean()\n",
    "print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "for i in range(N_CLASSES):\n",
    "  print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(), \"model-trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35812f3549a68c0c80e102abdb5fbba8158579bbfb7e11bdbba8ac28992cc519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
