# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.
"""

#Set of self-defined/modified functions which were used in cunjunction with https://github.com/huanzhang12/ZOO-Attack. repo.

!cp 'loader.sh' .
!bash loader.sh

import os
from google.colab import drive
import shutil
import torch
import torchvision
import numpy as np
import pandas as pd
import torch.nn as nn
import torch.backends.cudnn as cudnn
import cv2
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.models.densenet import DenseNet121_Weights
from PIL import Image
from google.colab.patches import cv2_imshow
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, classification_report
drive.mount('/content/drive')

DECREASE_FACTOR = 0.9   # 0<f<1, rate at which we shrink tau; larger is more accurate
MAX_ITERATIONS = 1000   # number of iterations to perform gradient descent
ABORT_EARLY = True      # abort gradient descent upon first valid solution
INITIAL_CONST = 1e-5    # the first value of c to start at
LEARNING_RATE = 5e-3    # larger values converge faster to less accurate results
LARGEST_CONST = 2e+1    # the largest value of c to go up to before giving up
REDUCE_CONST = False    # try to lower c each iteration; faster to set to false
TARGETED = True         # should we target one specific class? or just be wrong?
CONST_FACTOR = 2.0      # f>1, rate at which we increase constant, smaller better

cd drive/MyDrive/CS543_Project

N_CLASSES = 14
BATCH_SIZE = 64
CKPT_PATH = 'model.pth.tar'

CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',
'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']

class DenseNet121(nn.Module):
    def __init__(self, out_size):
        super(DenseNet121, self).__init__()
        self.densenet121 = torchvision.models.densenet121(weights=DenseNet121_Weights.DEFAULT)
        features = self.densenet121.classifier.in_features
        self.densenet121.classifier = nn.Sequential(
            nn.Linear(features, out_size),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.densenet121(x)
        return x

cudnn.benchmark = True

# initialize and load the model
model = DenseNet121(N_CLASSES).cuda()
model = torch.nn.DataParallel(model).cuda()

if os.path.isfile(CKPT_PATH):
  print("=> loading checkpoint")
  checkpoint = torch.load(CKPT_PATH)
  model.load_state_dict(checkpoint['state_dict'], strict=False)
  print("=> loaded checkpoint")
else:
  print("=> no checkpoint found")

data = pd.read_csv('cleaned.csv')
X, Y = data.iloc[:, 0], data.iloc[:, 1]

imList = []
i = 0
for i in range(30963):
res = os.path.join('images', X[i])
image = Image.open(res).convert('RGB')
npImage = np.array(image)
diff_ = np.diff(image,axis=0)
newCol = np.zeros((1,diff_.shape[1],diff_.shape[2]))
diff = np.vstack((diff_,newCol))
print(diff.shape)
#cv2_imshow(diff)
cv2_imshow(-0.07*diff+image)
#imList.append(image)

data['Finding Labels'].unique()

classNames = []
dict_ = {}
for i in range(100):
  string = data.iloc[i]['Finding Labels']
  if string not in classNames:
    classNames.append(string)
    dict_[string] = i

for label in classNames:
  i = dict_[label]
  res = os.path.join('images', X[i])
  image = Image.open(res).convert('RGB')
  npImage = np.array(image)
  diff_ = np.diff(image,axis=0)
  newCol = np.zeros((1,diff_.shape[1],diff_.shape[2]))
  diff = np.vstack((diff_,newCol))
  print(diff.shape)
  cv2_imshow(noise_factor*diff+image)


def getOutput(image,diff,noDiff):
    normalize = transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
    transform=transforms.Compose([
                              transforms.Resize(256),
                              transforms.TenCrop(224),
                              transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),
                              transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))
                              ])
  model.eval()
  if noDiff:
    i = transform(image)
  else:
    numpy_image = -0.07*diff+image
    i = transform(Image.fromarray(np.uint8(numpy_image)))
  n_crops, c, h, w = i.size()
  input = torch.autograd.Variable(i.view(-1, c, h, w).cuda())
  output = model(input)
  output_mean = output.view(n_crops, -1).mean(0)
  return output_mean


getOutput(image,diff,False) - getOutput(image,diff,True)

def NoiseAdd(classNames,dict_,noise_factor):
    max = 0
    maxI = -1
    for i in range(30963):
    res = os.path.join('images', X[i])
    image = Image.open(res).convert('RGB')
    diff_ = np.diff(image,axis=0)
    newCol = np.zeros((1,diff_.shape[1],diff_.shape[2]))
    diff = np.vstack((diff_,newCol))
    #cv2_imshow(0.1*diff+image)
    result = getOutput(image,diff,False) - getOutput(image,diff,True)
    if abs(result).mean() > max:
      max = abs(result).mean()
      maxI = i
  
def compare(x,y):
    return x != y
    shape = (1,model.image_size,model.image_size,model.num_channels)
    
def gradient_descent(self, sess, model):
    
    modifier = tf.Variable(np.zeros(shape,dtype=np.float32))

    tau = tf.placeholder(tf.float32, [])
    simg = tf.placeholder(tf.float32, shape)
    timg = tf.placeholder(tf.float32, shape)
    tlab = tf.placeholder(tf.float32, (1,model.num_labels))
    const = tf.placeholder(tf.float32, [])
    
    newimg = (tf.tanh(modifier + simg)/2)
    
    output = model.predict(newimg)
    orig_output = model.predict(tf.tanh(timg)/2)

    real = tf.reduce_sum((tlab)*output)
    other = tf.reduce_max((1-tlab)*output - (tlab*10000))

loss1 = tf.maximum(0.0,real-other)

    # sum up the losses
    loss2 = tf.reduce_sum(tf.maximum(0.0,tf.abs(newimg-tf.tanh(timg)/2)-tau))
    loss = const*loss1+loss2

    # setup the adam optimizer and keep track of variables we're creating
    start_vars = set(x.name for x in tf.global_variables())
    optimizer = tf.train.AdamOptimizer(LEARNING_RATE)
    train = optimizer.minimize(loss, var_list=[modifier])

    end_vars = tf.global_variables()
    new_vars = [x for x in end_vars if x.name not in start_vars]
    init = tf.variables_initializer(var_list=[modifier]+new_vars)

    def doit(oimgs, labs, starts, tt, CONST):
        # convert to tanh-space
        imgs = np.arctanh(np.array(oimgs)*1.999999)
        starts = np.arctanh(np.array(starts)*1.999999)

        # initialize the variables
        sess.run(init)
        while CONST < LARGEST_CONST:
            # try solving for each value of the constant
            print('try const', CONST)
            for step in range(MAX_ITERATIONS):
                feed_dict={timg: imgs, 
                           tlab:labs, 
                           tau: tt,
                           simg: starts,
                           const: CONST}
                if step%(MAX_ITERATIONS//10) == 0:
                    print(step,sess.run((loss,loss1,loss2),feed_dict=feed_dict))

                # perform the update step
                _, works = sess.run([train, loss], feed_dict=feed_dict)

                # it worked
                if works < .0001*CONST and (ABORT_EARLY or step == CONST-1):
                    get = sess.run(output, feed_dict=feed_dict)
                    works = compare(np.argmax(get), np.argmax(labs))
                    if works:
                        scores, origscores, nimg = sess.run((output,orig_output,newimg),feed_dict=feed_dict)
                        l2s=np.square(nimg-np.tanh(imgs)/2).sum(axis=(1,2,3))
                        
                        return scores, origscores, nimg, CONST

            # we didn't succeed, increase constant and try again
            CONST *= const_factor

    return doit    
def zooattack(imgs, targets):
    r = []
    for img,target in zip(imgs, targets):
        r.extend(attack_single(img, target))
    return np.array(r)

def GrayImageAttack(classNames,dict_,noise_factor, image):
    gray_img = np.ones((1024,1024,3)) 
    addedImage = NoiseAdd(classNames,dict_,noise_factor)
    while(np.)
res = os.path.join('images', X[53])
image = Image.open(res).convert('RGB')
cv2_imshow(image)

def attack_single(img, target):
    """
    Run the attack on a single image and label
    """

    # the previous image
    prev = np.copy(img).reshape((1,model.image_size,model.image_size,model.num_channels))
    tau = 1.0
    const = INITIAL_CONST
    
    while tau > 1./256:
        # try to solve given this tau value
        res = grad([np.copy(img)], [target], np.copy(prev), tau, const)
        if res == None:
            # the attack failed, we return this as our final answer
            return prev

        scores, origscores, nimg, const = res
        if REDUCE_CONST: const /= 2

        # the attack succeeded, reduce tau and try again

        actualtau = np.max(np.abs(nimg-img))

        if actualtau < tau:
            tau = actualtau

        print("Tau",tau)

        prev = nimg
        tau *= DECREASE_FACTOR
    return prev

# npImage = np.array(image)
# diff_ = np.diff(image,axis=0)
# newCol = np.zeros((1,diff_.shape[1],diff_.shape[2]))
# diff = np.vstack((diff_,newCol))
# diff2 = np.vstack((-0.096*diff+image,50*np.ones((10,diff_.shape[1],diff_.shape[2]))))
# cv2_imshow(diff2)

